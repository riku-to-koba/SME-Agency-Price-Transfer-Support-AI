"""Orchestrator + mode agents for 3-tier architecture.

- Mode detection: LLM first (Bedrock Haiku). LLMãŒä½¿ãˆãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ã€‚
- ä½ä¿¡é ¼ãªã‚‰ãƒ’ã‚¢ãƒªãƒ³ã‚°è³ªå•ã‚’è¿”ã—ã€ãã‚Œä»¥å¤–ã¯Mode1/Mode2ã¸å§”è­²ã€‚
- Mode1Agent: lightweight general consultation (stateless).
- Mode2Agent: price-transfer specialist (wraps existing PriceTransferAgent).

ã€ä¿®æ­£å†…å®¹ã€‘
- åˆå›ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Orchestratorç®¡ç†ã«
- ä¼šè©±å±¥æ­´æ§‹ç¯‰ã‚’æ”¹å–„ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼+ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆä¸¡æ–¹ï¼‰
- ãƒ¢ãƒ¼ãƒ‰æ‰¿è«¾ãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…
- ãƒ’ã‚¢ãƒªãƒ³ã‚°ã®å¤šæ®µéšå¯¾å¿œ
- è‡ªç„¶ãªä¼šè©±èª¿ã®ãƒ’ã‚¢ãƒªãƒ³ã‚°
- LLMãƒ™ãƒ¼ã‚¹ã®æ‰¿è«¾/æ‹’å¦åˆ¤å®š
"""
from __future__ import annotations

import json
import re
from typing import Dict, List, Optional, Tuple

from agent.mode1 import Mode1Agent
from agent.mode2 import Mode2Agent


class ModeClassifier:
    """LLM-based mode classifier. LLMå¿…é ˆã€‚"""

    def __init__(self):
        self.model = None
        self.init_error: Optional[str] = None
        try:
            from strands.models import BedrockModel
            import boto3

            session = boto3.Session(profile_name="bedrock_use_only", region_name="ap-northeast-1")
            self.model = BedrockModel(
                model_id="jp.anthropic.claude-haiku-4-5-20251001-v1:0",
                temperature=0.2,
                max_tokens=1024,
                streaming=False,
                boto_session=session,
            )
        except Exception as e:
            self.model = None
            self.init_error = f"Bedrockãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"

    async def classify(self, user_input: str, history: str) -> Tuple[str, str, float, Optional[str]]:
        """Return (mode, reason, confidence, clarification)."""
        if not self.model:
            raise RuntimeError(self.init_error or "LLMãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚èªè¨¼æƒ…å ±ã‚„ãƒªãƒ¼ã‚¸ãƒ§ãƒ³è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        system_prompt = (
            "ã‚ãªãŸã¯ä¾¡æ ¼è»¢å«æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šæ‹…å½“ã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°ç™ºè©±ã¨ç›´è¿‘ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±å±¥æ­´ã‹ã‚‰ã€ä»¥ä¸‹ã‚’JSONã§è¿”ã—ã¦ãã ã•ã„ã€‚"
            "- mode: 'mode1' (ã‚ˆã‚ãšçµŒå–¶ç›¸è«‡) ã¾ãŸã¯ 'mode2' (ä¾¡æ ¼è»¢å«ãƒ»å€¤ä¸Šã’äº¤æ¸‰ç³»)"
            "- reason: åˆ¤å®šç†ç”±ã‚’ç°¡æ½”ã«"
            "- confidence: 0.0ã€œ1.0 ã®ç¢ºä¿¡åº¦"
            "- clarification: confidenceãŒ0.6æœªæº€ã®ã¨ãã®ã¿ã€ãƒ¢ãƒ¼ãƒ‰ã‚’æ±ºã‚ã‚‹ãŸã‚ã®å…·ä½“çš„ãªè³ªå•ã‚’2ã€œ3è¡Œã§è¿”ã™ã€‚é«˜ã„å ´åˆã¯ç©ºæ–‡å­—ã§å¯"
            "åˆ¤å®šã®æŒ‡é‡:"
            " ä¾¡æ ¼äº¤æ¸‰/å€¤ä¸Šã’/å˜ä¾¡/åŸä¾¡è¨ˆç®—/è¦‹ç©/ã‚³ã‚¹ãƒˆ/ä¸‹è«‹æ³•/è²·ã„ãŸãŸã/å–å¼•æ¡ä»¶/æ”¯æ‰•æ¡ä»¶/äº¤æ¸‰æº–å‚™ã¯ mode2ã€‚"
            " è³‡é‡‘ç¹°ã‚Š/äººæ/è²©è·¯/äº‹æ¥­æ‰¿ç¶™/çµ„ç¹”/ãƒãƒ¼ã‚±ãªã©äº¤æ¸‰ã«ç›´çµã—ãªã„ç›¸è«‡ã¯ mode1ã€‚"
            " å‡ºåŠ›ã¯å¿…ãšJSONã®ã¿ã€‚"
        )
        user_prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›:
{user_input}

ç›´è¿‘å±¥æ­´ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã®ã¿æŠœç²‹ã€æœ€å¤§800æ–‡å­—ï¼‰:
{history[-800:] if history else "ãªã—"}

å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšJSONã®ã¿ï¼‰:
{{
  "mode": "mode1",
  "reason": "çŸ­ã„èª¬æ˜",
  "confidence": 0.5,
  "clarification": "ç¢ºä¿¡ãŒä½ã„å ´åˆã ã‘è³ªå•ã€‚é«˜ã„ã¨ãã¯ç©ºæ–‡å­—ã¾ãŸã¯çœç•¥å¯"
}}
"""
        try:
            # BedrockModelã‚’Agentã§ãƒ©ãƒƒãƒ—ã—ã¦éåŒæœŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å®Ÿè¡Œ
            from strands import Agent
            temp_agent = Agent(model=self.model, tools=[], system_prompt=system_prompt)

            # stream_asyncã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åé›†
            resp_chunks = []
            async for event in temp_agent.stream_async(user_prompt):
                if "data" in event:
                    resp_chunks.append(event["data"])

            resp = "".join(resp_chunks)
            
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆ```json ... ``` å½¢å¼ã«å¯¾å¿œï¼‰
            json_match = re.search(r'```json\s*(.*?)\s*```', resp, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # ```ãªã—ã®ç´”ç²‹ãªJSONã‚’è©¦ã™
                json_str = resp.strip()
            
            data = json.loads(json_str)
            return (
                data.get("mode", "mode1"),
                data.get("reason", "llm_reason"),
                max(0.0, min(1.0, float(data.get("confidence", 0.7)))),
                data.get("clarification") or None,
            )
        except json.JSONDecodeError as e:
            # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§mode1ã‚’è¿”ã™
            print(f"[WARN] JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€mode1ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {str(e)}")
            return ("mode1", "JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼", 0.5, None)
        except Exception as e:
            raise RuntimeError(f"LLMãƒ¢ãƒ¼ãƒ‰åˆ¤å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}") from e

    async def judge_consent(self, user_input: str, context: str) -> Tuple[str, str]:
        """LLMã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‰¿è«¾/æ‹’å¦ã‚’åˆ¤å®šã™ã‚‹ã€‚
        
        Returns:
            (åˆ¤å®šçµæœ, ç†ç”±)
            åˆ¤å®šçµæœ: "consent" | "rejection" | "unclear"
        """
        if not self.model:
            raise RuntimeError(self.init_error or "LLMãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

        system_prompt = (
            "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’åˆ¤å®šã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãŒã€ææ¡ˆã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã«å¯¾ã—ã¦ã€Œæ‰¿è«¾ã€ã€Œæ‹’å¦ã€ã€Œä¸æ˜ç¢ºã€ã®ã„ãšã‚Œã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚\n\n"
            "ã€åˆ¤å®šåŸºæº–ã€‘\n"
            "- consentï¼ˆæ‰¿è«¾ï¼‰: è‚¯å®šçš„ãªè¿”ç­”ã€åŒæ„ã€é€²ã‚ã¦ã»ã—ã„ã¨ã„ã†æ„æ€è¡¨ç¤º\n"
            "  ä¾‹: ã€Œã¯ã„ã€ã€ŒãŠé¡˜ã„ã—ã¾ã™ã€ã€Œãã‚Œã§ã„ã„ã€ã€Œå¤§ä¸ˆå¤«ã€ã€Œé€²ã‚ã¦ã€ã€ŒOKã€ã€Œã„ã„ã§ã™ã‚ˆã€ã€Œãã†ã—ã¦ãã ã•ã„ã€\n"
            "- rejectionï¼ˆæ‹’å¦ï¼‰: å¦å®šçš„ãªè¿”ç­”ã€æ–­ã‚Šã€åˆ¥ã®ã“ã¨ã‚’å¸Œæœ›\n"
            "  ä¾‹: ã€Œã„ã„ãˆã€ã€Œé•ã„ã¾ã™ã€ã€Œã‚„ã‚ã¦ã€ã€Œãã‚Œã¯é•ã†ã€ã€Œåˆ¥ã®ç›¸è«‡ãŒã—ãŸã„ã€ã€Œä»Šã¯ã„ã„ã€\n"
            "- unclearï¼ˆä¸æ˜ç¢ºï¼‰: è³ªå•ã€ç¢ºèªã€ã¾ãŸã¯æ‰¿è«¾/æ‹’å¦ãŒåˆ¤æ–­ã§ããªã„ç™ºè¨€\n"
            "  ä¾‹: ã€Œè©³ã—ãæ•™ãˆã¦ã€ã€Œã©ã†ã„ã†ã“ã¨ï¼Ÿã€ã€Œã‚‚ã†å°‘ã—èª¬æ˜ã—ã¦ã€ã€Œã¡ã‚‡ã£ã¨å¾…ã£ã¦ã€\n\n"
            "å‡ºåŠ›ã¯å¿…ãšJSONã®ã¿ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        user_prompt = f"""
ç›´å‰ã®AIã®ææ¡ˆ:
{context}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¿”ç­”:
{user_input}

å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšJSONã®ã¿ï¼‰:
{{
  "judgment": "consent",
  "reason": "åˆ¤å®šç†ç”±ã‚’ç°¡æ½”ã«"
}}
"""
        try:
            from strands import Agent
            temp_agent = Agent(model=self.model, tools=[], system_prompt=system_prompt)

            resp_chunks = []
            async for event in temp_agent.stream_async(user_prompt):
                if "data" in event:
                    resp_chunks.append(event["data"])

            resp = "".join(resp_chunks)
            
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            json_match = re.search(r'```json\s*(.*?)\s*```', resp, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = resp.strip()
            
            data = json.loads(json_str)
            judgment = data.get("judgment", "unclear")
            reason = data.get("reason", "")
            
            # æœ‰åŠ¹ãªå€¤ã‹ãƒã‚§ãƒƒã‚¯
            if judgment not in ("consent", "rejection", "unclear"):
                judgment = "unclear"
            
            return (judgment, reason)
        except Exception as e:
            print(f"[WARN] æ‰¿è«¾åˆ¤å®šã‚¨ãƒ©ãƒ¼ã€unclearã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {str(e)}")
            return ("unclear", "åˆ¤å®šã‚¨ãƒ©ãƒ¼")


class OrchestratorAgent:
    """3-tier orchestrator coordinating Mode1 and Mode2 agents."""

    def __init__(self):
        self.sessions: Dict[str, dict] = {}
        self.mode_classifier = ModeClassifier()

    def create_session(self, session_id: str, user_info: Optional[dict] = None):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã€åˆå›ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨­å®š"""
        session = {
            "session_id": session_id,
            "mode": None,  # åˆå›ã¯ãƒ¢ãƒ¼ãƒ‰æœªç¢ºå®š
            "mode_confirmed": False,  # ãƒ¢ãƒ¼ãƒ‰æ‰¿è«¾ãƒ•ãƒ©ã‚°
            "messages": [],
            "current_step": None,
            "mode2_progress": {"completed_steps": [], "current_step": None, "data": {}},
            "user_info": user_info or {},
            "agents": {
                "mode1": Mode1Agent(),
                "mode2": None,  # lazy init
            },
        }

        # åˆå›ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’OrchestratorãŒç®¡ç†
        welcome_message = self._generate_welcome_message()
        session["messages"].append({"role": "assistant", "content": welcome_message})

        self.sessions[session_id] = session
        return session

    def _generate_welcome_message(self) -> str:
        """åˆå›ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆï¼ˆè‡ªç„¶ãªä¼šè©±èª¿ï¼‰"""
        return (
            "ã“ã‚“ã«ã¡ã¯ï¼ä¸­å°ä¼æ¥­ä¾¡æ ¼è»¢å«ã‚µãƒãƒ¼ãƒˆAIã§ã™ã€‚\n\n"
            "è³‡é‡‘ç¹°ã‚Šã€äººæã€è²©è·¯æ‹¡å¤§ã€ä¾¡æ ¼äº¤æ¸‰ã€äº‹æ¥­æ‰¿ç¶™â€¦\n"
            "çµŒå–¶ã®ãŠæ‚©ã¿ã€ã©ã‚“ãªã“ã¨ã§ã‚‚æ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„ã€‚\n\n"
            "ä»Šæ—¥ã¯ã©ã‚“ãªã“ã¨ã§ãŠå›°ã‚Šã§ã™ã‹ï¼Ÿ"
        )

    def get_session(self, session_id: str) -> Optional[dict]:
        return self.sessions.get(session_id)

    def ensure_mode2_agent(self, session: dict):
        if session["agents"]["mode2"] is None:
            session["agents"]["mode2"] = Mode2Agent(
                current_step=session.get("current_step"),
                user_info=session.get("user_info"),
            )
        return session["agents"]["mode2"]

    def update_mode(self, session: dict, new_mode: str) -> bool:
        if session["mode"] != new_mode:
            session["mode"] = new_mode
            return True
        return False

    def _build_history_context(self, session: dict, max_turns: int = 5) -> str:
        """ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ + ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆä¸¡æ–¹ï¼‰

        Args:
            session: ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
            max_turns: å–å¾—ã™ã‚‹æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆ1ã‚¿ãƒ¼ãƒ³ = ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ + AIå¿œç­”ï¼‰

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸä¼šè©±å±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆ
        """
        messages = session.get("messages", [])

        # ç›´è¿‘ã®ã‚¿ãƒ¼ãƒ³åˆ†ã‚’å–å¾—ï¼ˆmax_turns * 2 ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
        recent_messages = messages[-(max_turns * 2):] if messages else []

        history_parts = []
        for msg in recent_messages:
            role_label = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg["role"] == "user" else "AI"
            content = msg.get("content", "")
            # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚‹ï¼ˆ1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ€å¤§300æ–‡å­—ï¼‰
            if len(content) > 300:
                content = content[:300] + "..."
            history_parts.append(f"{role_label}: {content}")

        return "\n".join(history_parts)


    def _generate_initial_clarification(self) -> str:
        """åˆå›ãƒ’ã‚¢ãƒªãƒ³ã‚°è³ªå•ï¼ˆè‡ªç„¶ãªä¼šè©±èª¿ï¼‰"""
        return "ãªã‚‹ã»ã©ã€‚ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã©ã‚“ãªçŠ¶æ³ã§ã€ä½•ã«å›°ã£ã¦ã„ã‚‹ã®ã‹èã‹ã›ã¦ãã ã•ã„ã€‚"

    def _generate_followup_clarification(self, session: dict) -> str:
        """2å›ç›®ä»¥é™ã®ãƒ’ã‚¢ãƒªãƒ³ã‚°è³ªå•ï¼ˆè‡ªç„¶ãªä¼šè©±èª¿ï¼‰"""
        return "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã©ã‚“ãªã“ã¨ã§ãŠæ‰‹ä¼ã„ã§ããã†ã§ã™ã‹ï¼Ÿ"

    def _request_mode_consent(self, mode: str, reason: str) -> str:
        """ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã®æ‰¿è«¾ã‚’æ±‚ã‚ã‚‹ï¼ˆè‡ªç„¶ãªä¼šè©±èª¿ï¼‰"""
        if mode == "mode2":
            return (
                f"ãªã‚‹ã»ã©ã€{reason}ã¨ã„ã†ã“ã¨ã§ã™ã­ã€‚\n\n"
                "ä¾¡æ ¼äº¤æ¸‰ãƒ»å€¤ä¸Šã’ã®ç›¸è«‡ã§ã—ãŸã‚‰ã€å°‚é–€ãƒ¢ãƒ¼ãƒ‰ã§è©³ã—ãã‚µãƒãƒ¼ãƒˆã§ãã¾ã™ã€‚\n"
                "å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã€ã‚³ã‚¹ãƒˆè©¦ç®—ã€äº¤æ¸‰ã‚·ãƒŠãƒªã‚ªã®ä½œæˆãªã©ã€æœ¬æ ¼çš„ãªæº–å‚™ã‚’ãŠæ‰‹ä¼ã„ã—ã¾ã™ã‚ˆã€‚\n\n"
                "å°‚é–€ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¦é€²ã‚ã¦ã‚‚ã„ã„ã§ã™ã‹ï¼Ÿ"
            )
        else:
            return (
                f"ãªã‚‹ã»ã©ã€{reason}ã¨ã„ã†ã“ã¨ã§ã™ã­ã€‚\n\n"
                "çµŒå–¶å…¨èˆ¬ã®ã”ç›¸è«‡ã¨ã—ã¦ã€ä¸€ç·’ã«è€ƒãˆã¦ã„ãã¾ã—ã‚‡ã†ã€‚\n"
                "ã“ã®ã¾ã¾é€²ã‚ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ"
            )

    async def stream(self, session: dict, message: str):
        """Route to appropriate agent and yield streaming events."""
        print(f"[DEBUG] Orchestrator.stream() called with message: {message[:50]}...")
        print(f"[DEBUG] Session mode: {session.get('mode')}")

        # === ã‚¹ãƒ†ãƒƒãƒ—1: ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ + ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆä¸¡æ–¹ï¼‰ ===
        history_text = self._build_history_context(session)

        # === ã‚¹ãƒ†ãƒƒãƒ—3: LLMã§ãƒ¢ãƒ¼ãƒ‰åˆ¤å®š ===
        print(f"[DEBUG] Starting mode classification...")
        print(f"[DEBUG] History text length: {len(history_text)}")
        try:
            mode, mode_reason, mode_confidence, clarification = await self.mode_classifier.classify(
                message, history_text
            )
            print(f"[DEBUG] Classification result: mode={mode}, confidence={mode_confidence}")
        except Exception as e:
            print(f"[DEBUG] Classification ERROR: {str(e)}")
            import traceback
            traceback.print_exc()
            yield {"type": "error", "error": str(e)}
            return

        # === ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ’ã‚¢ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆconfidence ãŒä½ã„å ´åˆï¼‰ ===
        if mode_confidence < 0.35:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆåˆå›ã‹2å›ç›®ä»¥é™ã‹ï¼‰
            user_message_count = len([m for m in session.get("messages", []) if m.get("role") == "user"])

            if user_message_count == 0:
                # åˆå›ãƒ’ã‚¢ãƒªãƒ³ã‚°
                clarify_msg = clarification or self._generate_initial_clarification()
            else:
                # 2å›ç›®ä»¥é™ã®ãƒ’ã‚¢ãƒªãƒ³ã‚°
                clarify_msg = clarification or self._generate_followup_clarification(session)

            session["messages"].append({"role": "user", "content": message})
            session["messages"].append({"role": "assistant", "content": clarify_msg})
            yield {"data": clarify_msg}
            return

        # === ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ¼ãƒ‰ç¢ºå®šï¼ˆè¨±å¯ãªã—ã§ç§»è¡Œï¼‰ ===
        mode_changed = (session["mode"] != mode)

        if mode_changed:
            # ãƒ¢ãƒ¼ãƒ‰ã‚’æ›´æ–°
            self.update_mode(session, mode)
            session["mode_confirmed"] = True
            
            # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´ã‚’é€šçŸ¥
            yield {
                "type": "mode_update",
                "mode": mode,
                "reason": mode_reason,
                "confidence": mode_confidence,
            }
            
            # çŸ­ã„ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            if mode == "mode2":
                confirm_msg = (
                    "ä¾¡æ ¼è»¢å«ã®å°‚é–€ãƒ¢ãƒ¼ãƒ‰ã§å¯¾å¿œã—ã¾ã™ã€‚\n\n"
                    "ğŸ“Š å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®èª¿æŸ»ãƒ»åˆ†æ\n"
                    "ğŸ’° ã‚³ã‚¹ãƒˆè©¦ç®—ã¨é©æ­£ä¾¡æ ¼ã®ç®—å‡º\n"
                    "ğŸ“„ ç”³å…¥æ›¸ãƒ»è¦‹ç©æ›¸ãªã©ã®æ–‡æ›¸ä½œæˆ\n"
                    "ğŸ­ äº¤æ¸‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n\n"
                    "ãªã©ã®ã‚µãƒãƒ¼ãƒˆãŒã§ãã¾ã™ã€‚\n\n"
                )
            else:
                confirm_msg = "çµŒå–¶å…¨èˆ¬ã®ã”ç›¸è«‡ã¨ã—ã¦å¯¾å¿œã—ã¾ã™ã€‚\n\n"
            
            yield {"data": confirm_msg}
            session["messages"].append({"role": "assistant", "content": confirm_msg.strip()})

        # === ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ  ===
        session["messages"].append({"role": "user", "content": message})

        # === ã‚¹ãƒ†ãƒƒãƒ—7: é©åˆ‡ãªå­ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸å§”è­² ===
        # æ³¨æ„: ä¼šè©±å±¥æ­´ã¸ã®è¿½åŠ ã¯api/main.pyã®append_assistant_messageã§è¡Œã†
        # ã“ã“ã§ã¯è¿½åŠ ã—ãªã„ï¼ˆç”»åƒã‚¿ã‚°ç­‰ã‚’é™¤å»ã—ãŸã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹ãŸã‚ï¼‰

        if mode == "mode2":
            agent = self.ensure_mode2_agent(session)
            async for event in agent.stream_async(message):
                yield event
        else:
            agent: Mode1Agent = session["agents"]["mode1"]
            turn_index = len([m for m in session.get("messages", []) if m.get("role") == "assistant"])
            async for event in agent.stream_async(
                message,
                user_info=session.get("user_info"),
                turn_index=turn_index,
            ):
                yield event

        # æ³¨æ„: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”ã®å±¥æ­´è¿½åŠ ã¯ api/main.py ã® append_assistant_message ã§è¡Œã†
        # ç†ç”±: ãƒ„ãƒ¼ãƒ«çµæœï¼ˆ[CHART_IMAGE]ã‚¿ã‚°ç­‰ï¼‰ã‚’é™¤å»ã—ãŸã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹ãŸã‚

    def append_assistant_message(self, session: dict, content: str):
        session["messages"].append({"role": "assistant", "content": content})

